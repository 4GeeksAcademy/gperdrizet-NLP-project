{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language processing: spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import helper_functions as funcs\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "RANDOM_SEED = 315\n",
    "CLASS_WEIGHT = 'balanced'\n",
    "N_SPLITS = 3\n",
    "\n",
    "CV = StratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Hyperparameter search settings\n",
    "N_JOBS = 1\n",
    "N_ITER = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading\n",
    "\n",
    "### 1.1. Load data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into dataframe\n",
    "data_df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv')\n",
    "\n",
    "# Drop duplicates if any\n",
    "data_df.drop_duplicates(inplace=True)\n",
    "data_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Save a local copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for raw data\n",
    "Path('../data/raw').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save a local copy of the raw data\n",
    "data_df.to_parquet('../data/raw/urls.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1. Label frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = data_df['is_spam'].value_counts()\n",
    "\n",
    "not_spam = label_counts.iloc[0]\n",
    "spam = label_counts.iloc[1]\n",
    "\n",
    "print(f'URLs are {(not_spam/(spam + not_spam)*100):.1f}% not spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. URL length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['URL_length'] = data_df['url'].str.len().tolist()\n",
    "\n",
    "plt.title('URL length distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.ylabel('URLs')\n",
    "plt.hist(data_df['URL_length'], bins=30, color='black')\n",
    "plt.show()\n",
    "\n",
    "print(f\"URL length mean: {np.mean(data_df['URL_length']):.0f}\")\n",
    "print(f\"URL length min: {min(data_df['URL_length']):.0f}\")\n",
    "print(f\"URL length max: {max(data_df['URL_length']):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Short URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_urls = data_df[data_df['URL_length'] < 20]\n",
    "short_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Long URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_urls = data_df[data_df['URL_length'] > 200]\n",
    "long_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['is_spam'] = data_df['is_spam'].astype(str)\n",
    "data_df['is_spam'] = data_df['is_spam'].replace({'True': '1', 'False': '0'})\n",
    "data_df['is_spam'] = data_df['is_spam'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. URL vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the URLs using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_urls = vectorizer.fit_transform(train_df['url'])\n",
    "test_urls = vectorizer.transform(test_df['url'])\n",
    "\n",
    "# Get the words from the vector model\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "train_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Mean TF-IDF value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean TF-IDF value for each feature\n",
    "feature_means = np.mean(train_urls.toarray(), axis=1)\n",
    "\n",
    "plt.title('Mean TF-IDF distribution')\n",
    "plt.xlabel('Mean TF-IDF')\n",
    "plt.ylabel('Features')\n",
    "plt.hist(feature_means, bins=30, color='black')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM model\n",
    "\n",
    "### 3.1. Baseline model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the support vector machine classifier with defaults\n",
    "naive_svc = SVC(class_weight=CLASS_WEIGHT, random_state=RANDOM_SEED)\n",
    "\n",
    "# Cross-validate the default model on the encoded training data\n",
    "scores = cross_val_score(\n",
    "    naive_svc,\n",
    "    train_urls,\n",
    "    train_df['is_spam'],\n",
    "    cv=CV,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Save the baseline cross-validation scores for later\n",
    "cross_val_scores = {\n",
    "    'Model': ['Naive SVC']*N_SPLITS,\n",
    "    'Score': list(scores)\n",
    "}\n",
    "\n",
    "print(f'Naive SVC cross validation accuracy: {np.mean(scores)*100:.1f}+/-{np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. SVC hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameter search space\n",
    "hyperparameters = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'shrinking': [True, False],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}\n",
    "\n",
    "# Instantiate a new model\n",
    "model = SVC(class_weight=CLASS_WEIGHT, random_state=RANDOM_SEED)\n",
    "\n",
    "# Set up the grid search\n",
    "grid = GridSearchCV(model, hyperparameters, scoring='accuracy', cv=CV, n_jobs=N_JOBS)\n",
    "\n",
    "# Run the search\n",
    "optimization_results = grid.fit(train_urls, train_df['is_spam'])\n",
    "\n",
    "# Recover winning model & hyperparameters\n",
    "optimized_svc = grid.best_estimator_\n",
    "best_hyperparameters = grid.best_params_\n",
    "\n",
    "print(f'Best hyperparameters:\\n')\n",
    "\n",
    "for key, val in best_hyperparameters.items():\n",
    "    print(f' {key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.plot_cross_validation(optimization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the optimized model on the encoded training data\n",
    "scores = cross_val_score(\n",
    "    optimized_svc,\n",
    "    train_urls,\n",
    "    train_df['is_spam'],\n",
    "    cv=CV,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Save the optimized cross-validation scores for later\n",
    "cross_val_scores['Model'].extend(['Optimized SVC']*N_SPLITS)\n",
    "cross_val_scores['Score'].extend(scores)\n",
    "\n",
    "print(f'Optimized SVC cross validation accuracy: {np.mean(scores)*100:.1f}+/-{np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. TFIDFVectorizer + SVC hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "svc = SVC(class_weight=CLASS_WEIGHT, random_state=RANDOM_SEED)\n",
    "\n",
    "# Create pipeline with PCA, scaling, and classifier\n",
    "pipe = Pipeline(steps=[('TFIDF', tfidf), ('SVC', svc)])\n",
    "\n",
    "hyperparameters = {\n",
    "    'TFIDF__strip_accents': ['ascii', 'unicode', None],\n",
    "    'TFIDF__stop_words': ['english', stopwords.words('english'), None],\n",
    "    'TFIDF__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "    'TFIDF__max_df': uniform(loc=0.0009, scale=0.9991),\n",
    "    'TFIDF__min_df': uniform(loc=0.0, scale=0.0004),\n",
    "    'TFIDF__max_features': randint(1, len(feature_names)),\n",
    "    'TFIDF__binary': [True, False],\n",
    "    'TFIDF__norm': ['l1', 'l2', None],\n",
    "    'TFIDF__use_idf': [True, False],\n",
    "    'TFIDF__smooth_idf': [True, False],\n",
    "    'TFIDF__sublinear_tf': [True, False],\n",
    "    'SVC__C': loguniform(10**-2, 100.0),\n",
    "    'SVC__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'SVC__degree': [1, 2, 3],\n",
    "    'SVC__gamma': ['scale', 'auto'],\n",
    "    'SVC__shrinking': [True, False],\n",
    "    'SVC__decision_function_shape': ['ovo', 'ovr']\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    hyperparameters,\n",
    "    return_train_score=True,     # Return training scores for analysis\n",
    "    cv=CV,                       # Use stratified shuffle split for cross-validation\n",
    "    n_jobs=N_JOBS,               # Use all available CPU cores\n",
    "    n_iter=N_ITER,               # Number of parameter combinations to try\n",
    "    random_state=RANDOM_SEED     # Ensure reproducible results\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "optimization_results = grid.fit(train_df['url'], train_df['is_spam'])\n",
    "\n",
    "# Recover winning model & hyperparameters\n",
    "optimized_tfidf_svc = grid.best_estimator_\n",
    "best_hyperparameters = grid.best_params_\n",
    "\n",
    "print(f'Best hyperparameters:\\n')\n",
    "\n",
    "for key, val in best_hyperparameters.items():\n",
    "    print(f' {key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.plot_cross_validation(optimization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the optimized model on the encoded training data\n",
    "scores = cross_val_score(\n",
    "    optimized_tfidf_svc,\n",
    "    train_df['url'],\n",
    "    train_df['is_spam'],\n",
    "    cv=CV,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Save the optimized cross-validation scores for later\n",
    "cross_val_scores['Model'].extend(['Optimized TFIDF + SVC']*N_SPLITS)\n",
    "cross_val_scores['Score'].extend(scores)\n",
    "\n",
    "print(f'Optimized TFIDF + SVC cross validation accuracy: {np.mean(scores)*100:.1f}+/-{np.std(scores)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(pd.DataFrame.from_dict(cross_val_scores), x='Model', y='Score')\n",
    "plt.title('Model cross-validation performance comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tfidf_svc.fit(train_df['url'], train_df['is_spam'],)\n",
    "predictions = optimized_tfidf_svc.predict(test_df['url'])\n",
    "\n",
    "accuracy = accuracy_score(test_df['is_spam'], predictions)*100\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(test_df['is_spam'], predictions, normalize='true')\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "_ = cm_disp.plot()\n",
    "\n",
    "plt.title(f'Test set performance\\noverall accuracy: {accuracy:.1f}%')\n",
    "plt.xlabel('Predicted outcome')\n",
    "plt.ylabel('True outcome')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
